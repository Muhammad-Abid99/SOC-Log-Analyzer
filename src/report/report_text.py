# SPDX-FileCopyrightText: 2025 G. Mohammad <ghmuhammad324@gmail.com>
# SPDX-License-Identifier: Apache-2.0

import datetime

def generate_text_report(summary: dict, detection_alerts: list, output_dir: str) -> None:
    """
    Generates a professional, enhanced text summary report for SOC-Log-Analyzer.

    Args:
        summary (dict): Pre-computed summary stats from logs, e.g., total_logs, top_users, etc.
        detection_alerts (list): List of alert dicts with keys like 'type', 'message', 'timestamp', 'severity'.
        output_dir (str): Directory path to save the text report file.
    """

    # Calculate duration as human readable string
    start_time = summary.get("start_time")
    end_time = summary.get("end_time")

    try:
        start_dt = datetime.datetime.fromisoformat(start_time)
        end_dt = datetime.datetime.fromisoformat(end_time)
        duration_sec = (end_dt - start_dt).total_seconds()
        hours = int(duration_sec // 3600)
        minutes = int((duration_sec % 3600) // 60)
        duration_str = f"{hours}h {minutes}m"
    except Exception:
        duration_str = "N/A"

    # Prepare top users and event IDs
    top_users = summary.get("top_users", {})
    top_users_sorted = sorted(top_users.items(), key=lambda x: x[1], reverse=True)[:5]

    top_event_ids = summary.get("top_event_ids", {})
    top_event_ids_sorted = sorted(top_event_ids.items(), key=lambda x: x[1], reverse=True)[:5]

    # Count alerts by severity
    alerts_count = len(detection_alerts)
    severity_counts = {}
    for alert in detection_alerts:
        sev = alert.get("severity", "Unknown")
        severity_counts[sev] = severity_counts.get(sev, 0) + 1

    # Detect potential anomalies (example: off-hours logons)
    anomalies = []
    for alert in detection_alerts:
        if alert.get("type") == "Unusual Logon Time":
            anomalies.append(f"- Off-hours logon: User '{alert.get('user')}' at {alert.get('timestamp')}")

    # Rare events example: event IDs with very low count (<=2)
    rare_events = [eid for eid, count in summary.get("top_event_ids", {}).items() if count <= 2]
    if rare_events:
        anomalies.append(f"- Rare events detected: {', '.join(str(e) for e in rare_events)}")

    # Compose report lines
    lines = []
    lines.append("=" * 60)
    lines.append("SOC INCIDENT SUMMARY REPORT")
    
    # ====== Added Report Generated Timestamp ======
    report_generated_at = datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")
    lines.append(f"Report Generated At: {report_generated_at}")
    lines.append("")

    lines.append("=" * 60)
    lines.append("")
    lines.append("📊 Dataset Overview")
    lines.append(f"- Total Logs: {summary.get('total_logs', 'N/A')}")
    lines.append(f"- Time Range: {start_time} → {end_time}")
    lines.append(f"- Duration: {duration_str}")
    lines.append(f"- Unique Hosts: {summary.get('unique_hosts', 'N/A')}")
    lines.append("")

    lines.append("👤 Top 5 Active Users")
    for i, (user, count) in enumerate(top_users_sorted, 1):
        lines.append(f"{i}. {user} ({count} events)")
    lines.append("")

    lines.append("🔍 Top 5 Event IDs")
    for i, (eid, count) in enumerate(top_event_ids_sorted, 1):
        lines.append(f"{i}. {eid} → {count} occurrences")
    lines.append("")

    lines.append("🚨 Detection Alerts")
    if alerts_count == 0:
        lines.append("- No detection alerts triggered.")
    else:
        lines.append(f"- Total alerts: {alerts_count}")
        for sev, count in severity_counts.items():
            lines.append(f"  - {sev} severity: {count}")
    lines.append("")

    lines.append("⚠️ Potential Anomalies")
    if anomalies:
        lines.extend(anomalies)
    else:
        lines.append("- None detected.")
    lines.append("")

    lines.append("=" * 60)

    # ====== Added Total Detection Alerts before footer ======
    lines.insert(-1, f"Total Detection Alerts: {alerts_count}")

    lines.append("Generated by SOC-Log-Analyzer | For Internal SOC Use Only")
    lines.append("=" * 60)

    # ====== Added GitHub Link Footer ======
    lines.append("")
    lines.append("Visit https://github.com/Muhammad-Abid99/SOC-Log-Analyzer for more info.")

    # Write to file
    report_path = f"{output_dir}/log_summary.txt"
    with open(report_path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))
